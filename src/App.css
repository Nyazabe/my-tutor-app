import React, { useState, useEffect, useRef } from 'react';
import { initializeApp } from 'firebase/app';
import { getAuth, signInAnonymously, signInWithCustomToken, onAuthStateChanged } from 'firebase/auth';

// Use lucide-react icons for a clean look
const Mic = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" x2="12" y1="19" y2="22"/></svg>
);
const Send = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><line x1="22" x2="11" y1="2" y2="13"/><polygon points="22 2 15 22 11 13 2 9 22 2"/></svg>
);
const Paperclip = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="m21.44 11.05-9.19 9.19a6 6 0 0 1-8.49-8.49l8.57-8.57A4 4 0 1 1 18 8.84l-8.57 8.57a2 2 0 0 1-2.83-2.83l8.49-8.49"/><line x1="10" x2="10" y1="10" y2="10"/></svg>
);
const Headphones = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M3 14h3a2 2 0 0 1 2 2v3a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-7a9 9 0 0 1 18 0v7a2 2 0 0 1-2 2h-1a2 2 0 0 1-2-2v-3a2 2 0 0 1 2-2h3"/></svg>
);
const X = () => (
    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg>
);

// Define the main App component
const App = () => {
    // --- State Management ---
    // Initialize chat history with the welcome message from the start.
    // The system prompt is not a message, so it's not included here.
    const [language, setLanguage] = useState('English');
    const languageMap = {
        'English': { promptInstruction: 'Respond exclusively in English.', welcome: "Hello! I'm your Socratic programming tutor. I can speak English, French, Lingala, and Swahili. I can also help with code in text-based files, images, or through voice input. What are you working on today?", voiceCode: 'en-US', ttsVoice: 'Kore' },
        'French': { promptInstruction: 'Répondez exclusivement en français.', welcome: "Bonjour! Je suis votre tuteur de programmation socratique. Sur quoi travaillez-vous aujourd'hui?", voiceCode: 'fr-FR', ttsVoice: 'Puck' },
        'Lingala': { promptInstruction: 'Répondez exclusivement en Lingala.', welcome: "Mbote! Naza socratic programme tuteur na yo. Ozali kosala nini lelo?", voiceCode: 'en-US', ttsVoice: 'Kore' },
        'Swahili': { promptInstruction: 'Jibu pekee katika Kiswahili.', welcome: "Habari! Mimi ni mwalimu wako wa programu ya Kiswahili. Unafanya kazi gani leo?", voiceCode: 'sw-KE', ttsVoice: 'Kore' }
    };

    const [chatHistory, setChatHistory] = useState([
        { role: "model", parts: [{ text: languageMap['English'].welcome }] }
    ]);
    const [userInput, setUserInput] = useState('');
    const [isLoading, setIsLoading] = useState(false);
    const [isRecording, setIsRecording] = useState(false);
    const [uploadedFile, setUploadedFile] = useState(null);
    const [statusMessage, setStatusMessage] = useState('');
    const [authReady, setAuthReady] = useState(false);
    const [db, setDb] = useState(null);
    const [auth, setAuth] = useState(null);
    
    const chatHistoryRef = useRef(null);
    const recognitionRef = useRef(null);
    const finalTranscriptRef = useRef('');

    // --- LLM API Configuration ---
    const apiKey = "";
    const apiUrlBase = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent`;
    const apiUrl = apiKey ? `${apiUrlBase}?key=${apiKey}` : apiUrlBase;

    // --- Socratic Prompt & Language Mapping ---
    const socraticBasePrompt = `
        You are a Socratic programming tutor for students in Sub-Saharan Africa. Your purpose is to guide a student to a solution
        by asking questions and prompting critical thinking, not by providing the answer directly.
        The student is a learner in a developing country.

        **Core Behavioral Rules:**
        1.  **Never provide the full code solution.** You may provide small, conceptual code snippets to illustrate a point, but avoid a complete, runnable solution.
        2.  **Break down problems into smaller, manageable steps.** If the student asks for a complex program, ask them what the first step would be.
        3.  **Ask guiding questions.** Focus on questions that prompt the student to reflect on their own logic, like "What is the next step?", "Why this approach?", or "What does this function do?"
        4.  **Use culturally and contextually relevant analogies.** Where appropriate, use simple, relatable examples from a local context.
        5.  **Maintain a supportive and encouraging tone.**
        6.  **Do not get stuck in a loop of only asking "What's the next step?".** Vary your questions to promote different computational thinking skills.
        The student will ask you a question about a programming problem. Your response should be a Socratic question or a hint, not the solution.
        
        When an image is provided, analyze the content and formulate a Socratic question based on it. When a text file is provided, treat its content as the user's message.
    `;

    const getSocraticSystemPrompt = () => {
        const instruction = languageMap[language].promptInstruction;
        return socraticBasePrompt + `\n\n${instruction}`;
    };

    // --- Utility Functions for Audio ---
    const base64ToArrayBuffer = (base64) => {
        const binaryString = window.atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        return bytes.buffer;
    };

    const pcmToWav = (pcmData, sampleRate) => {
        const wavData = new ArrayBuffer(44 + pcmData.length * 2);
        const view = new DataView(wavData);
        let offset = 0;

        const writeString = (str) => {
            for (let i = 0; i < str.length; i++) {
                view.setUint8(offset++, str.charCodeAt(i));
            }
        };
        const writeUint32 = (value) => {
            view.setUint32(offset, value, true);
            offset += 4;
        };
        const writeUint16 = (value) => {
            view.setUint16(offset, value, true);
            offset += 2;
        };

        writeString('RIFF');
        writeUint32(36 + pcmData.length * 2);
        writeString('WAVE');
        writeString('fmt ');
        writeUint32(16);
        writeUint16(1); // PCM format
        writeUint16(1); // Mono
        writeUint32(sampleRate);
        writeUint32(sampleRate * 2);
        writeUint16(2);
        writeUint16(16);
        writeString('data');
        writeUint32(pcmData.length * 2);

        for (let i = 0; i < pcmData.length; i++) {
            view.setInt16(offset, pcmData[i], true);
            offset += 2;
        }
        return new Blob([view], { type: 'audio/wav' });
    };

    // --- TTS Functionality ---
    const speakText = async (text, buttonElement) => {
        const currentVoice = languageMap[language].ttsVoice;

        if (buttonElement) {
            buttonElement.innerHTML = `<div class="audio-loading-spinner"></div>`;
        }

        const payload = {
            contents: [{ parts: [{ text: text }] }],
            generationConfig: {
                responseModalities: ["AUDIO"],
                speechConfig: {
                    voiceConfig: { prebuiltVoiceConfig: { voiceName: currentVoice } }
                }
            },
            model: "gemini-2.5-flash-preview-tts"
        };
        const ttsApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

        let retryCount = 0;
        let response;
        let success = false;
        while (retryCount < 5 && !success) {
            try {
                response = await fetch(ttsApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (response.status === 429) {
                    await new Promise(res => setTimeout(res, Math.pow(2, retryCount) * 1000));
                    retryCount++;
                } else if (!response.ok) {
                    throw new Error(`TTS API responded with status: ${response.status}`);
                } else {
                    success = true;
                }
            } catch (error) {
                await new Promise(res => setTimeout(res, Math.pow(2, retryCount) * 1000));
                retryCount++;
            }
        }
        
        if (buttonElement) {
            buttonElement.innerHTML = '<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><path d="M3 14h3a2 2 0 0 1 2 2v3a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-7a9 9 0 0 1 18 0v7a2 2 0 0 1-2 2h-1a2 2 0 0 1-2-2v-3a2 2 0 0 1 2-2h3"/></svg>';
        }

        if (success) {
            const result = await response.json();
            const part = result?.candidates?.[0]?.content?.parts?.[0];
            const audioData = part?.inlineData?.data;
            const mimeType = part?.inlineData?.mimeType;

            if (audioData && mimeType && mimeType.startsWith("audio/")) {
                try {
                    const sampleRateMatch = mimeType.match(/rate=(\d+)/);
                    const sampleRate = sampleRateMatch ? parseInt(sampleRateMatch[1], 10) : 16000;
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play();

                    audio.onended = () => URL.revokeObjectURL(audioUrl);
                } catch (e) {
                    console.error('Audio playback error:', e);
                }
            }
        }
    };

    // --- Main LLM communication function ---
    const processMessage = async (userMessage, autoPlayAudio = false) => {
        if (!userMessage && !uploadedFile) return;

        let payloadParts = [];
        let displayMessage = userMessage;
        
        // Handle file upload
        if (uploadedFile) {
            if (uploadedFile.type.startsWith('image/')) {
                payloadParts.push({ text: userMessage });
                payloadParts.push({ 
                    inlineData: { mimeType: uploadedFile.type, data: uploadedFile.base64 } 
                });
                displayMessage = `Uploaded file: ${uploadedFile.name}` + (userMessage ? `\n\n${userMessage}` : "");
            } else if (uploadedFile.text) {
                payloadParts.push({ text: uploadedFile.text });
                if (userMessage) {
                    payloadParts.push({ text: `User's message: ${userMessage}`});
                }
                displayMessage = `Uploaded file: ${uploadedFile.name}` + (userMessage ? `\n\n${userMessage}` : "");
            }
        } else {
            payloadParts.push({ text: userMessage });
            displayMessage = userMessage;
        }
        
        const chatHistoryMessage = { role: "user", parts: [{ text: displayMessage }] };
        setChatHistory(prev => [...prev, chatHistoryMessage]);
        
        setIsLoading(true);
        setUserInput('');
        setUploadedFile(null); // Clear file immediately after sending
        setStatusMessage(''); // Clear status message immediately after sending

        // Construct the full conversation history for the API call
        // The first message is the model's welcome, which we don't send to the API
        const conversationHistory = [...chatHistory.slice(1), { role: "user", parts: payloadParts }];
        
        const payload = {
            contents: conversationHistory, 
            systemInstruction: { parts: [{ text: getSocraticSystemPrompt() }] }
        };

        let retryCount = 0;
        let response;
        let success = false;
        while (retryCount < 5 && !success) {
            try {
                response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                if (response.status === 429) {
                    await new Promise(res => setTimeout(res, Math.pow(2, retryCount) * 1000));
                    retryCount++;
                } else if (!response.ok) {
                    throw new Error(`API responded with status: ${response.status}`);
                } else {
                    success = true;
                }
            } catch (error) {
                await new Promise(res => setTimeout(res, Math.pow(2, retryCount) * 1000));
                retryCount++;
            }
        }
        setIsLoading(false);

        if (success) {
            const result = await response.json();
            const aiResponseText = result.candidates?.[0]?.content?.parts?.[0]?.text;

            if (aiResponseText) {
                const newAiMessage = { role: "model", parts: [{ text: aiResponseText }] };
                setChatHistory(prev => [...prev, newAiMessage]);
                if (autoPlayAudio) {
                    speakText(aiResponseText, null);
                }
            } else {
                setStatusMessage("Sorry, I'm having trouble with that. Can you try rephrasing?");
            }
        } else {
            setStatusMessage("Sorry, the server is not responding. Please try again later.");
        }
    };

    // --- Handlers for user interactions ---
    const handleSend = () => {
        if (isRecording) {
            recognitionRef.current?.stop();
            processMessage(finalTranscriptRef.current, true);
            finalTranscriptRef.current = '';
        } else {
            processMessage(userInput.trim(), false);
        }
    };

    const handleKeyPress = (e) => {
        if (e.key === 'Enter' && !isRecording) {
            handleSend();
        }
    };
    
    const handleRemoveFile = () => {
        setUploadedFile(null);
        setStatusMessage('');
    };

    const handleFileChange = (e) => {
        const file = e.target.files[0];
        if (!file) return;

        const supportedTextExtensions = ['.txt', '.py', '.php'];
        const isTextFile = supportedTextExtensions.some(ext => file.name.endsWith(ext));
        const isImage = file.type.startsWith('image/');
        
        if (isImage || isTextFile) {
            const reader = new FileReader();
            reader.onload = (e) => {
                setUploadedFile({
                    dataUrl: e.target.result,
                    base64: e.target.result.split(',')[1],
                    type: file.type,
                    name: file.name,
                    text: isTextFile ? e.target.result : null
                });
                setStatusMessage(`File selected: ${file.name}`);
            };
            if (isImage) {
                reader.readAsDataURL(file);
            } else {
                reader.readAsText(file);
            }
        } else {
            setStatusMessage("Socratic AI Tutor does not currently handle that kind of format.");
            e.target.value = '';
            setUploadedFile(null);
        }
    };

    // --- Effects and Initial Setup ---
    // This effect is now only for setting the initial welcome message based on language.
    // The chatHistory is initialized once at the start.
    useEffect(() => {
      const initialMessage = { role: "model", parts: [{ text: languageMap[language].welcome }] };
      setChatHistory([initialMessage]);
    }, [language]);

    useEffect(() => {
        chatHistoryRef.current?.scrollTo({ top: chatHistoryRef.current.scrollHeight, behavior: 'smooth' });
    }, [chatHistory, isLoading]);
    
    // --- Web Speech API Setup ---
    useEffect(() => {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        if (SpeechRecognition) {
            const recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = languageMap[language].voiceCode;

            recognition.onstart = () => {
                setIsRecording(true);
                finalTranscriptRef.current = '';
            };
            recognition.onresult = (event) => {
                let interimTranscript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscriptRef.current += transcript;
                    } else {
                        interimTranscript += transcript;
                    }
                }
                setUserInput(finalTranscriptRef.current + interimTranscript);
            };
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error === 'not-allowed') {
                    setStatusMessage('Please enable microphone access.');
                }
                setIsRecording(false);
            };
            recognition.onend = () => {
                setIsRecording(false);
            };
            recognitionRef.current = recognition;

            return () => {
                recognition.stop();
            };
        }
    }, [language]);

    const handleVoiceInput = () => {
        if (isRecording) {
            recognitionRef.current?.stop();
        } else {
            recognitionRef.current?.start();
        }
    };

    // Firebase initialization logic
    useEffect(() => {
        // Initialize Firebase services using global variables
        try {
            const firebaseConfig = typeof __firebase_config !== 'undefined' ? JSON.parse(__firebase_config) : null;
            const initialAuthToken = typeof __initial_auth_token !== 'undefined' ? __initial_auth_token : null;

            if (!firebaseConfig) {
                console.error("Firebase config not found. The app will run without Firebase features.");
                setAuthReady(true);
                return;
            }

            const app = initializeApp(firebaseConfig);
            const authInstance = getAuth(app);
            setAuth(authInstance);

            const signIn = async () => {
                if (initialAuthToken) {
                    await signInWithCustomToken(authInstance, initialAuthToken);
                } else {
                    await signInAnonymously(authInstance);
                }
                setAuthReady(true);
            };

            const unsubscribe = onAuthStateChanged(authInstance, (user) => {
                if (!user) {
                    signIn();
                } else {
                    setAuthReady(true);
                }
            });

            return () => unsubscribe();
        } catch (error) {
            console.error("Firebase initialization or sign-in failed:", error);
            setAuthReady(true);
        }
    }, []);

    return (
        <div className="flex flex-col h-screen bg-gray-100 antialiased">
            {/* CSS for the loading spinner */}
            <style>
                {`
                .loading-container {
                    display: flex;
                    justify-content: flex-start;
                    align-items: center;
                    margin-left: 20px;
                }
                .loading-dot {
                    width: 8px;
                    height: 8px;
                    background-color: #3b82f6;
                    border-radius: 50%;
                    margin: 0 4px;
                    animation: bounce 1s infinite ease-in-out both;
                }
                .loading-dot:nth-child(1) {
                    animation-delay: -0.32s;
                }
                .loading-dot:nth-child(2) {
                    animation-delay: -0.16s;
                }
                .audio-loading-spinner {
                    width: 20px;
                    height: 20px;
                    border: 3px solid #f3f3f3;
                    border-top: 3px solid #3b82f6;
                    border-radius: 50%;
                    animation: spin 1s linear infinite;
                    margin-left: 8px;
                }
                @keyframes bounce {
                    0%, 80%, 100% { transform: scale(0); }
                    40% { transform: scale(1.0); }
                }
                @keyframes spin {
                    0% { transform: rotate(0deg); }
                    100% { transform: rotate(360deg); }
                }
                .user-message {
                    background-color: #3b82f6;
                    color: white;
                    align-self: flex-end;
                }
                .ai-message {
                    background-color: #e5e7eb;
                    color: black;
                    align-self: flex-start;
                }
                `}
            </style>
            <div className="flex-1 flex flex-col max-w-2xl mx-auto w-full bg-white rounded-lg shadow-xl overflow-hidden md:my-4">
                <header className="bg-blue-600 p-4 text-white text-center rounded-t-lg flex justify-between items-center">
                    <h1 className="text-xl font-bold flex-1 text-center">Socratic AI Tutor</h1>
                    <select
                        className="bg-white text-blue-600 rounded-lg p-1 text-sm font-semibold focus:outline-none"
                        value={language}
                        onChange={(e) => setLanguage(e.target.value)}
                    >
                        {Object.keys(languageMap).map(lang => (
                            <option key={lang} value={lang}>{lang}</option>
                        ))}
                    </select>
                </header>

                <main ref={chatHistoryRef} className="flex-1 overflow-y-auto p-4 flex flex-col space-y-4">
                    {chatHistory.map((msg, index) => {
                        const isUser = msg.role === 'user';
                        const messageText = msg.parts?.[0]?.text;
                        
                        return (
                            <div
                                key={index}
                                className={`chat-message p-3 rounded-xl shadow-md break-words flex items-end ${isUser ? 'user-message ml-auto' : 'ai-message'}`}
                            >
                                <div className="flex-1">
                                    {messageText && <p>{messageText}</p>}
                                </div>
                                {!isUser && (
                                    <button className="audio-btn" onClick={(e) => speakText(messageText, e.currentTarget)}>
                                        <Headphones />
                                    </button>
                                )}
                            </div>
                        );
                    })}
                    {isLoading && (
                        <div className="loading-container">
                            <div className="loading-dot" />
                            <div className="loading-dot" />
                            <div className="loading-dot" />
                        </div>
                    )}
                </main>

                <div className="p-4 bg-gray-100 flex items-center border-t border-gray-200 rounded-b-lg">
                    <label htmlFor="file-upload" className="p-2 cursor-pointer text-gray-500 hover:text-blue-600 transition-colors">
                        <Paperclip />
                        <input id="file-upload" type="file" className="hidden" accept="image/*,.txt,.py,.php" onChange={handleFileChange} />
                    </label>
                    <button
                        className={`p-2 transition-colors focus:outline-none ${isRecording ? 'text-red-500' : 'text-gray-500 hover:text-blue-600'}`}
                        onClick={handleVoiceInput}
                    >
                        <Mic />
                    </button>
                    <div className="flex-1 relative mx-2">
                        {uploadedFile && (
                            <div className="absolute top-1/2 left-2 transform -translate-y-1/2 bg-blue-100 text-blue-800 text-xs px-2 py-1 rounded-full flex items-center space-x-1">
                                <span>{uploadedFile.name}</span>
                                <button onClick={handleRemoveFile} className="text-blue-600 hover:text-blue-900">
                                    <X />
                                </button>
                            </div>
                        )}
                        <input
                            type="text"
                            className={`w-full p-3 border-2 border-gray-300 rounded-full focus:outline-none focus:border-blue-500 transition-colors ${uploadedFile ? 'pl-24' : ''}`}
                            placeholder={isRecording ? "Listening..." : "Type a message or use the icons..."}
                            value={userInput}
                            onChange={(e) => setUserInput(e.target.value)}
                            onKeyDown={handleKeyPress}
                        />
                    </div>
                    <button
                        className="p-3 bg-blue-600 text-white rounded-full shadow-lg hover:bg-blue-700 transition-colors focus:outline-none"
                        onClick={handleSend}
                    >
                        <Send />
                    </button>
                </div>
            </div>

            {statusMessage && (
                <div
                    className="fixed bottom-8 left-1/2 -translate-x-1/2 p-3 bg-red-500 text-white rounded-lg shadow-lg transition-opacity duration-300"
                >
                    {statusMessage}
                </div>
            )}
        </div>
    );
};

export default App;
